{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DpZPbRvRuLZv"
      },
      "outputs": [],
      "source": [
        "from mlagents_envs.environment import UnityEnvironment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = UnityEnvironment(file_name=None, seed=1, side_channels=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1rwnVq2qyoO"
      },
      "source": [
        "### Behavior Specs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrD0rSv92T8A"
      },
      "source": [
        "#### Get the Behavior Specs from the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a7KatdThq7OV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the behavior : Builder?team=0\n"
          ]
        }
      ],
      "source": [
        "# We will only consider the first Behavior\n",
        "behavior_name = list(env.behavior_specs)[0]\n",
        "print(f\"Name of the behavior : {behavior_name}\")\n",
        "spec = env.behavior_specs[behavior_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1L8DHADrAbe"
      },
      "source": [
        "#### Get the Observation Space from the Behavior Specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PqDTV5mSrJF5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations :  1\n",
            "Is there a visual observation ? True\n"
          ]
        }
      ],
      "source": [
        "# Examine the number of observations per Agent\n",
        "print(\"Number of observations : \", len(spec.observation_specs))\n",
        "\n",
        "# Is there a visual observation ?\n",
        "# Visual observation have 3 dimensions: Height, Width and number of channels\n",
        "vis_obs = any(len(spec.shape) == 3 for spec in spec.observation_specs)\n",
        "print(\"Is there a visual observation ?\", vis_obs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ObservationSpec(shape=(20, 20, 7), dimension_property=(<DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.NONE: 1>), observation_type=<ObservationType.DEFAULT: 0>, name='GridSensor-OneHot')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spec.observation_specs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVLN_wbG1G5-"
      },
      "source": [
        "#### Get the Action Space from the Behavior Specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M9zk1-az1L-G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 discrete actions\n",
            "Action number 0 has 9 different options\n"
          ]
        }
      ],
      "source": [
        "# Is the Action continuous or multi-discrete ?\n",
        "if spec.action_spec.continuous_size > 0:\n",
        "  print(f\"There are {spec.action_spec.continuous_size} continuous actions\")\n",
        "if spec.action_spec.is_discrete():\n",
        "  print(f\"There are {spec.action_spec.discrete_size} discrete actions\")\n",
        "\n",
        "\n",
        "# How many actions are possible ?\n",
        "#print(f\"There are {spec.action_size} action(s)\")\n",
        "\n",
        "# For discrete actions only : How many different options does each action has ?\n",
        "if spec.action_spec.discrete_size > 0:\n",
        "  for action, branch_size in enumerate(spec.action_spec.discrete_branches):\n",
        "    print(f\"Action number {action} has {branch_size} different options\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cX07SGw22Lm"
      },
      "source": [
        "### Stepping the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5p0s0prfsQ"
      },
      "source": [
        "#### Get the steps from the Environment\n",
        "You can do this with the `env.get_steps(behavior_name)` method. If there are multiple behaviors in the Environment, you can call this method with each of the behavior's names.\n",
        "_Note_ This will not move the simulation forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ePZtcHXUrjyf"
      },
      "outputs": [],
      "source": [
        "decision_steps, terminal_steps = env.get_steps(behavior_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Oj3ix530mx"
      },
      "source": [
        "#### Set actions for each behavior\n",
        "You can set the actions for the Agents of a Behavior by calling `env.set_actions()` you will need to specify the behavior name and pass a tensor of dimension 2. The first dimension of the action must be equal to the number of Agents that requested a decision during the step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KB-nxfbw337g"
      },
      "outputs": [],
      "source": [
        "env.set_actions(behavior_name, spec.action_spec.random_action(len(decision_steps)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQCybRs84cmq"
      },
      "source": [
        "#### Move the simulation forward\n",
        "Call `env.step()` to move the simulation forward. The simulation will progress until an Agent requestes a decision or terminates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nl3K40ZR4bh2"
      },
      "outputs": [],
      "source": [
        "env.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9gdextn2vJy"
      },
      "source": [
        "### Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAMqnnddr8Xo"
      },
      "source": [
        "#### Show the observations for one of the Agents\n",
        "`DecisionSteps.obs` is a tuple containing all of the observations for all of the Agents with the provided Behavior name.\n",
        "Each value in the tuple is an observation tensor containing the observation data for all of the agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decision_steps.obs[0][0, :, :, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y60u21sys8kA"
      },
      "source": [
        "### Run the Environment for a few episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "a2uQUsoMtIUK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rewards for episode 0 is 0.0\n"
          ]
        }
      ],
      "source": [
        "for episode in range(1):\n",
        "  env.reset()\n",
        "  decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
        "  tracked_agent = -1 # -1 indicates not yet tracking\n",
        "  done = False # For the tracked_agent\n",
        "  episode_rewards = 0 # For the tracked_agent\n",
        "  while not done:\n",
        "    # Track the first agent we see if not tracking\n",
        "    # Note : len(decision_steps) = [number of agents that requested a decision]\n",
        "    if tracked_agent == -1 and len(decision_steps) >= 1:\n",
        "      tracked_agent = decision_steps.agent_id[0]\n",
        "\n",
        "    # Generate an action for all agents\n",
        "    action = spec.action_spec.random_action(len(decision_steps))\n",
        "\n",
        "    # Set the actions\n",
        "    env.set_actions(behavior_name, action)\n",
        "\n",
        "    # Move the simulation forward\n",
        "    env.step()\n",
        "\n",
        "    # Get the new simulation results\n",
        "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
        "    if tracked_agent in decision_steps: # The agent requested a decision\n",
        "      episode_rewards += decision_steps[tracked_agent].reward\n",
        "    if tracked_agent in terminal_steps: # The agent terminated its episode\n",
        "      episode_rewards += terminal_steps[tracked_agent].reward\n",
        "      done = True\n",
        "  print(f\"Total rewards for episode {episode} is {episode_rewards}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-3grXNEtJPa"
      },
      "source": [
        "### Close the Environment to free the port it is using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vdWG6_SqtNtv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closed environment\n"
          ]
        }
      ],
      "source": [
        "env.close()\n",
        "print(\"Closed environment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Colab-UnityEnvironment-1-Run.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
